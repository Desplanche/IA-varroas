{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://www.tensorflow.org/tutorials/images/classification\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras \n",
    "from keras import layers  #pas de tensorflow.kerras\n",
    "from keras.models import Sequential #idem\n",
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "\n",
    "print('data_dir', data_dir,'image_count', image_count)\n",
    "varroas = list(data_dir.glob('varroas/*'))\n",
    "PIL.Image.open(str(varroas[0]))\n",
    "\n",
    "batch_size = 200\n",
    "img_height = 22\n",
    "img_width = 22\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "for image_batch, labels_batch in train_ds: #image_batch ?\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break\n",
    "\n",
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Augmentation des données\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "# Créons un nouveau réseau de neurones avec tf.keras.layers.Dropout \n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# Compiler et entraîner le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "epochs = 200 # 200\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "# Visualisez les résultats de l'entraînement\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# sauvegarde du model \n",
    "# !mkdir -p saved_model\n",
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('my_model_200_1.h5')\n",
    "# Prédire sur de nouvelles données\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code est une implémentation d'un modèle de classification d'images à l'aide de TensorFlow et Keras. Il est écrit en Python.\n",
    "\n",
    "Le code commence par importer les bibliothèques nécessaires, notamment Matplotlib, NumPy, PIL, TensorFlow et Keras. Il définit également la taille de l'image d'entrée, la taille du lot et les répertoires de formation et de validation.\n",
    "\n",
    "Il utilise image_dataset_from_directory pour charger les données d'entraînement et de validation à partir des répertoires respectifs. Il normalise également les images en utilisant Rescaling et applique l'augmentation de données avec RandomFlip, RandomRotation, et RandomZoom.\n",
    "\n",
    "Le modèle est construit à l'aide de Sequential et comprend plusieurs couches de convolution et de regroupement, une couche de baisse aléatoire et deux couches denses. Il utilise l'optimiseur Adam et la fonction de perte SparseCategoricalCrossentropy pour la classification multiclasse.\n",
    "\n",
    "Le modèle est ensuite entraîné avec les données d'entraînement et de validation, et l'historique d'entraînement est stocké pour l'analyse. Enfin, les résultats d'entraînement sont tracés à l'aide de Matplotlib et le modèle est enregistré.\n",
    "\n",
    "Notez que certaines parties du code sont commentées. Par exemple, le code pour télécharger les images de fleurs est en commentaire, car il est supposé que les images ont déjà été téléchargées et sont disponibles dans le répertoire spécifié."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FLIP\n",
    "\n",
    "Le 'random flip' est appliqué de manière aléatoire sur les images en entrée. Cela signifie que pour chaque image, la fonction de transformation 'RandomFlip' décide si elle doit être retournée horizontalement (de gauche à droite) ou non. Cette transformation est une technique d'augmentation de données qui permet d'augmenter la diversité des images disponibles pour l'apprentissage et ainsi d'améliorer la capacité du modèle à généraliser sur de nouvelles données."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM ROTATION\n",
    "\n",
    "La fonction de transformation 'RandomRotation' est appliquée de manière aléatoire sur les images en entrée. Elle effectue une rotation aléatoire d'un angle compris entre -10 et 10 degrés, ce qui permet d'augmenter la diversité des images et donc d'améliorer la capacité du modèle à généraliser sur de nouvelles données. Cette transformation est également une technique d'augmentation de données couramment utilisée en vision par ordinateur."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random ZOOM\n",
    "\n",
    "La fonction de transformation 'RandomZoom' est également appliquée de manière aléatoire sur les images en entrée. Elle effectue un zoom aléatoire sur les images en entrée, en agrandissant ou en réduisant leur taille de manière aléatoire d'un facteur compris entre 0 et 10%. Cette transformation est une autre technique d'augmentation de données couramment utilisée en vision par ordinateur pour améliorer la robustesse du modèle à des variations d'échelle dans les images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEQUENTIAL\n",
    "\n",
    "En utilisant le module \"Sequential\" de la bibliothèque Keras, on peut créer des modèles de réseau de neurones en séquentiel, c'est-à-dire que les couches du modèle sont ajoutées les unes après les autres, dans l'ordre dans lequel elles doivent être exécutées.\n",
    "\n",
    "Dans le code donné, le modèle est créé à l'aide de \"Sequential\", et les différentes couches du réseau de neurones sont ajoutées les unes après les autres en utilisant la méthode \"add\". Ce modèle séquentiel est ensuite compilé et entraîné."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_batch label_batch\n",
    "\n",
    "image_batch et label_batch sont des variables contenant un batch d'images et les étiquettes correspondantes (ou labels) respectivement. Ces variables sont créées à partir de la variable train_ds qui est créée en utilisant la fonction tf.keras.utils.image_dataset_from_directory().\n",
    "\n",
    "Dans ce code, image_batch et label_batch sont utilisées pour vérifier la taille des lots (batch) d'images et de labels. La commande print(image_batch.shape) affiche la forme du batch d'images, qui devrait être de la forme (batch_size, img_height, img_width, num_channels), où batch_size est la taille du batch, img_height et img_width sont les dimensions des images, et num_channels est le nombre de canaux de couleur (3 pour une image en couleur RGB). De même, la commande print(labels_batch.shape) affiche la forme du batch de labels, qui devrait être de la forme (batch_size,)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
